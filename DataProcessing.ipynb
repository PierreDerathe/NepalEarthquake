{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4584c5c0",
   "metadata": {},
   "source": [
    "# Nepal Earthquake"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085a04d6",
   "metadata": {},
   "source": [
    "From: [Kaggle Nepal Earthquake](https://www.kaggle.com/datasets/imtkaggleteam/nepal-earthquake)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361a2277",
   "metadata": {},
   "source": [
    "### Context\n",
    "The Nepal Earthquake Severity Index is designed to provide an overview of estimated severity of impacts resulting from the earthquake of 25 April 2015. It is not a replacement for first hand damage and needs assessment information, but can support prioritisation during early stages of the response. It estimates severity based on: 1) the intensity of the earthquake; 2) population; 3) vulnerability of housing and population. This index will be updated to take account of: validation against first hand reports and improvements to the severity model; improved sources of data (quality, timeliness and scale); changing requirements as the response continues. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddd62d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn import datasets, decomposition, metrics, preprocessing, utils\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e065ebe7",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0862d188",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format=\"retina\"  # For high DPI display\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.set_context(\"notebook\")\n",
    "\n",
    "plotly.offline.init_notebook_mode(connected=True)\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "print(sklearn.__version__)  # Version tested on sklearn.__version__ == 1.3.x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd22f960",
   "metadata": {},
   "source": [
    "### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e79217",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pprint_var(**kwargs):\n",
    "    for k, v in kwargs.items():\n",
    "        print(f\"{k} = {v:.4g}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a5067b",
   "metadata": {},
   "source": [
    "#### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf1a7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = Path(\"data\")    # Change to your data folder\n",
    "assert DATA.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb087089",
   "metadata": {},
   "outputs": [],
   "source": [
    "eq_raw_df = pd.read_csv(DATA / \"nepal-earthquake-severity-index-latest.csv\", \n",
    "                        low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9153a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "eq_raw_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eq_raw_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['REGION', 'Hazard (Intensity)',\n",
    "       'Exposure', 'Housing', 'Poverty', 'Vulnerability',\n",
    "       'Severity category']\n",
    "eq_df = eq_raw_df[columns].copy()\n",
    "\n",
    "rename_dict = {\n",
    "    \"Hazard (Intensity)\": \"INTENSITY\",\n",
    "    \"Severity category\": \"SEVERITY_CATEGORY\",\n",
    "    \"Exposure\" : \"EXPOSURE\",\n",
    "    \"Housing\" : \"HOUSING\",\n",
    "    \"Poverty\" : \"POVERTY\",\n",
    "    \"Vulnerability\" : \"VULNERABILITY\"\n",
    "}\n",
    "# rename columns\n",
    "eq_df.rename(columns=rename_dict, inplace=True)\n",
    "eq_df\n",
    "\n",
    "del eq_raw_df\n",
    "eq_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the missing values\n",
    "eq_df.dropna(axis=\"index\", inplace=True)\n",
    "eq_df.reset_index(drop=True, inplace=True)\n",
    "eq_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.pairplot(eq_df.iloc[:, [1,2,3,4,5,6,7]])\n",
    "#plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "mask = np.triu(np.ones_like(eq_df.corr(numeric_only=True), dtype=bool))\n",
    "ax = sns.heatmap(\n",
    "    eq_df.corr(numeric_only=True),\n",
    "    cbar=True,\n",
    "    annot=True,\n",
    "    cmap=\"viridis\",\n",
    "    mask=mask,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(eq_df.describe())\n",
    "print(eq_df.describe(include='object'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eq_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform one-hot encoding on categorical features\n",
    "categorical_features = ['REGION']\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc.fit(eq_df[categorical_features])\n",
    "df_features_encoded = pd.DataFrame(enc.transform(eq_df[categorical_features]).toarray(), columns=enc.get_feature_names_out())\n",
    "# combine the one-hot encoded features with the numerical features\n",
    "eq_df = pd.concat([eq_df.drop(categorical_features, axis=1), df_features_encoded ], axis=1)\n",
    "eq_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eq_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "severity_mapping = {\n",
    "    \"Lowest\" : 0,\n",
    "    \"Low\" : 1,\n",
    "    \"Medium-Low\" : 2,\n",
    "    \"Medium-High\" : 3,\n",
    "    \"High\" : 4,\n",
    "    \"Highest\" : 5\n",
    "}\n",
    "eq_df['SEVERITY_CATEGORY'] = eq_df['SEVERITY_CATEGORY'].map(severity_mapping)\n",
    "eq_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets\n",
    "X = eq_df.drop(columns=[\"SEVERITY_CATEGORY\"])\n",
    "y = eq_df[\"SEVERITY_CATEGORY\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_val.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# report performance\n",
    "print(\"Linear Regression\")\n",
    "print(f\"R2 score: {metrics.r2_score(y_val, y_pred):.4g}\")\n",
    "print(f\"Balanced accuracy score: {metrics.balanced_accuracy_score(y_val, y_pred.round()):.4g}\")\n",
    "print(f\"MAE: {metrics.mean_absolute_error(y_val, y_pred):.4g}\")\n",
    "print(f\"MSE: {metrics.mean_squared_error(y_val, y_pred):.4g}\")\n",
    "print(f\"RMSE: {np.sqrt(metrics.mean_squared_error(y_val, y_pred)):.4g}\")\n",
    "\n",
    "print (\"Classificaiton report\")\n",
    "print(metrics.classification_report(y_val, y_pred.round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
